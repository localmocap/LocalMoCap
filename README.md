# SigAsia23_LocalMoCap



We present a novel locality-based learning method for cleaning and solving optical motion capture data. Given noisy marker data, we propose a new heterogeneous graph neural network which treats markers and joints as different types of nodes, and uses graph convolution operations to extract the local features of markers and joints and transform them to clean motions. To deal with anomaly markers (e.g. missing or with big tracking errors), the key insight is that a marker motion show strong locality in terms of its distances to its neighbor markers, which enables us to fill missing markers (e.g. due to occlusion). Additionally, we also identify marker outliers due to tracking errors by investigating their acceleration profiles. Finally, we propose a training regime based on representation learning and data augmentation, by training the model on data with masking. The masking schemes aim to mimic the missing and noisy markers often observed in the real data. Finally, we show that our method achieves high accuracy on multiple metrics across various datasets. Extensive comparison shows our method outperforms state-of-the-art methods in terms of prediction accuracy of missing marker position error by approximately 20\%, which leads to a further error reduction on the reconstructed joint rotation and position by 30\%. The code and data for this paper are available at \url{here](https://github.com/localmocap/SigAsia23_LocalMoCap)}.
